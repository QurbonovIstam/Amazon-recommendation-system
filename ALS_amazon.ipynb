{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Гибридная рекомендательная система для отзывов на товары Amazon\n",
        "\n",
        "Этот проект представляет собой пошаговое исследование и разработку рекомендательной системы для товаров Amazon. Цель — предсказать следующий товар, который может купить пользователь, на основе его предыдущих оценок. В ходе проекта были построены и оценены три различные модели: чистая коллаборативная фильтрация и две гибридные модели с текстовым переранжированием.\n",
        "\n",
        "## Набор данных\n",
        "###Контекст\n",
        "Этот набор данных содержит более 568 тысяч отзывов потребителей о различных товарах Amazon. Этот набор данных также доступен на других сайтах, связанных с этими наборами данных, но я счёл его полезным и поделился им здесь.\n",
        "\n",
        "###Содержание\n",
        "Этот набор данных содержит следующие атрибуты:\n",
        "\n",
        "\n",
        "*   Всего записей: 568454\n",
        "*   Всего столбцов: 10\n",
        "*  Доменное имя: amazon.com\n",
        "*  Расширение файла: CSV\n",
        "\n",
        "\n",
        "\n",
        "####Доступные поля: Id, ProductId, UserId, ProfileName, HelpfulnessNumerator, HelpfulnessDenomenator, Score, Time, Summary, Text\n",
        "Используется публичный датасет [Amazon Product Reviews](https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews) с платформы Kaggle.\n",
        "\n",
        "**Предварительная обработка:**\n",
        "1.  Данные были загружены и проанализированы на предмет пропусков.\n",
        "2.  Для построения надежных рекомендаций были отобраны только пользователи, оставившие 5 и более отзывов.\n",
        "3.  Данные были разделены на обучающую (`train_df`) и тестовую (`test_df`) выборки по принципу \"Leave-One-Out\": последняя по времени покупка каждого пользователя попала в тест, а все предыдущие — в обучение.\n",
        "\n",
        "##  Построенные модели\n",
        "\n",
        "### Модель 1: Коллаборативная фильтрация (ALS)\n",
        "\n",
        "В качестве базовой модели была использована коллаборативная фильтрация на основе метода **Alternating Least Squares (ALS)** из библиотеки `implicit`.\n",
        "\n",
        "-   **Подбор гиперпараметров**: С помощью поиска по сетке (`Grid Search`) были найдены оптимальные параметры для модели: `factors=100`, `regularization=0.01`, `iterations=25`.\n",
        "-   **Качество**: Модель показала очень хороший базовый результат.\n",
        "\n",
        "### Модель 2: Гибридная модель (ALS + TF-IDF на `Summary`)\n",
        "\n",
        "Первая попытка улучшить базовую модель заключалась в добавлении контентной логики. Идея была в том, чтобы переранжировать топ-20 кандидатов от ALS, используя текстовую схожесть на основе кратких описаний (`Summary`).\n",
        "\n",
        "-   **Метод**: Для каждого пользователя вычислялся средний TF-IDF вектор его истории покупок. Затем 20 кандидатов от ALS сортировались по косинусному сходству с этим вектором.\n",
        "-   **Результат**: Эта модель показала **значительное ухудшение** качества по сравнению с базовой. Вывод: краткие описания `Summary` слишком зашумлены и не несут достаточной информации для качественного переранжирования.\n",
        "\n",
        "### Модель 3: Улучшенная гибридная модель (ALS + TF-IDF на `Text`)\n",
        "\n",
        "Основываясь на выводах предыдущего шага, была построена вторая гибридная модель, но на этот раз TF-IDF векторы создавались на основе **полных текстов отзывов (`Text`)**.\n",
        "\n",
        "-   **Метод**: Логика переранжирования осталась той же, но использовалась новая, более подробная TF-IDF матрица.\n",
        "-   **Результат**: Эта модель показала **улучшение** по сравнению с чистой ALS. Это доказывает, что при достаточном количестве качественной текстовой информации контентное переранжирование способно улучшить результаты коллаборативной фильтрации."
      ],
      "metadata": {
        "id": "c_sv08qsZ9Qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем API Kaggle для загрузки необходимых данных"
      ],
      "metadata": {
        "id": "puBtx5viN84C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdFakSQGZbgP"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d 'arhamrumi/amazon-product-reviews'\n",
        "!unzip '/content/amazon-product-reviews.zip'\n",
        "! rm '/content/amazon-product-reviews.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "установка implicit"
      ],
      "metadata": {
        "id": "jT9RCLiTWsCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install implicit"
      ],
      "metadata": {
        "id": "ATpt75s1ofO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "импорт библиотеки"
      ],
      "metadata": {
        "id": "pMVA3jzRO8BZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hbWCPvx3njw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import coo_matrix\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAF_JrFv3sH1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Reviews.csv', index_col= 'Id')\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "6vnoXDMgPGWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "83_jDe2nl6eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "TxguXqp6VkCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь мы видим, что у нас немного пропущенных значений в столбцах ProfileName 26 и Summary 27. Поскольку эти данные не критичны для нашей задачи, мы не будем их удалять"
      ],
      "metadata": {
        "id": "NakpgTV0SBYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "ax = sns.histplot(\n",
        "    data=df,\n",
        "    x='Score',\n",
        "    bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5],\n",
        "    stat= 'percent',\n",
        "    discrete=True,\n",
        "    color=\"#4C72B0\",\n",
        "    edgecolor='black',\n",
        "    linewidth=1.2\n",
        ")\n",
        "for p in ax.patches:\n",
        "    percent = p.get_height()\n",
        "    ax.annotate(f'{percent:.1f}%',\n",
        "                (p.get_x() + p.get_width() / 2, percent),\n",
        "                ha='center', va='bottom', fontsize=11, color='black')\n",
        "\n",
        "\n",
        "plt.title('Оценки пользователей (1–5)', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Оценка', fontsize=12)\n",
        "plt.ylabel('Количество', fontsize=12)\n",
        "plt.xticks([1, 2, 3, 4, 5], fontsize=11)\n",
        "plt.yticks(fontsize=11)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wblt1DgtNM8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы видим на графике, что оценки 5 составляют 64% от всех, что является хорошим показателем и позволяет рекомендовать продукт"
      ],
      "metadata": {
        "id": "WGKk6YlCSwkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_counts = df.groupby('UserId').size()\n",
        "users_with_5_plus = user_counts[user_counts >= 5].index\n",
        "df_filtered = df[df['UserId'].isin(users_with_5_plus)]"
      ],
      "metadata": {
        "id": "DGSqZENXVv7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я решил оставить клиентов, которые оценили более 5 товаров, чтобы сохранить надёжный вектор довери"
      ],
      "metadata": {
        "id": "n9-uQCxITPBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time_based_split(df):\n",
        "    train_list = []\n",
        "    test_list = []\n",
        "\n",
        "    grouped = df.groupby('UserId')\n",
        "    for user, group in grouped:\n",
        "        group = group.sort_values('Time')  # сортируем по времени\n",
        "        train_list.append(group.iloc[:-1])  # все кроме последней покупки — в train\n",
        "        test_list.append(group.iloc[-1:])   # последняя покупка — в test\n",
        "\n",
        "    train_df = pd.concat(train_list).reset_index(drop=True)\n",
        "    test_df = pd.concat(test_list).reset_index(drop=True)\n",
        "    return train_df, test_df\n",
        "\n",
        "train_df, test_df = time_based_split(df_filtered)"
      ],
      "metadata": {
        "id": "hc80R0N0WjgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для разделения данных использовалась логика 'Leave-One-Out': последняя оценка каждого пользователя включена в тестовую выборку test_df, а все предыдущие — в обучающую train_df. Это позволяет моделировать реальный сценарий рекомендаций"
      ],
      "metadata": {
        "id": "LgKlLqtcT5Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Список уникальных пользователей и товаров на трейне\n",
        "unique_users = train_df['UserId'].unique()\n",
        "unique_items = train_df['ProductId'].unique()\n",
        "\n",
        "# Маппинг UserId → индекс и обратно\n",
        "user_map = {u: i for i, u in enumerate(unique_users)}\n",
        "item_map = {p: i for i, p in enumerate(unique_items)}\n",
        "\n",
        "# Инвертированные мапы (если потом нужно восстановить ID)\n",
        "user_map_inv = {i: u for u, i in user_map.items()}\n",
        "item_map_inv = {i: p for p, i in item_map.items()}\n",
        "\n",
        "# Добавляем индексированные значения в train/test\n",
        "train_df['user_idx'] = train_df['UserId'].map(user_map)\n",
        "train_df['item_idx'] = train_df['ProductId'].map(item_map)\n",
        "\n",
        "# В test_df возможны юзеры и товары, которых нет в трейне — фильтруем\n",
        "test_df = test_df[test_df['UserId'].isin(user_map)]\n",
        "test_df = test_df[test_df['ProductId'].isin(item_map)]\n",
        "\n",
        "test_df['user_idx'] = test_df['UserId'].map(user_map)\n",
        "test_df['item_idx'] = test_df['ProductId'].map(item_map)\n"
      ],
      "metadata": {
        "id": "H3onjUsvWsmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для построения матрицы взаимодействий и подачи данных в модель была выполнена индексация пользователей и товаров на основе обучающей выборки. Затем в тестовой выборке оставлены только те пользователи и товары, которые встречаются в трейне, и добавлены соответствующие индексы. Это позволяет обеспечить совместимость между train_df и test_df"
      ],
      "metadata": {
        "id": "TdytdpqjVGr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# log1p: сглаживает большие значения, полезно при оценках от 1 до 5\n",
        "ratings = coo_matrix(\n",
        "    (np.log1p(train_df['Score']), (train_df['user_idx'], train_df['item_idx'])),\n",
        "    shape=(len(user_map), len(item_map))\n",
        ")"
      ],
      "metadata": {
        "id": "T6YmhsePZMdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "используется логарифмическое преобразование оценок **log1p** что позволяет уменьшить влияние выбросов и более сбалансированно обучать модель. Матрица создаётся в формате coo_matrix, где строки — пользователи, столбцы — товары, а значения — логарифмированные оценки."
      ],
      "metadata": {
        "id": "uxTX1Fx1VYVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель **AlternatingLeastSquares** из библиотеки **implicit** обучается на транспонированной разреженной матрице item-user взаимодействий и позволяет формировать персонализированные рекомендации по логарифмированным оценкам."
      ],
      "metadata": {
        "id": "eKovfuucWANL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем в CSR формат — оптимален для ALS\n",
        "ratings_csr = ratings.tocsr()\n",
        "\n",
        "# Обучаем ALS\n",
        "model = AlternatingLeastSquares(factors=100, regularization=0.01, iterations=15)\n",
        "model.fit(ratings_csr)"
      ],
      "metadata": {
        "id": "NW2TJUm-oUtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из тестовой выборки для каждого пользователя выбирается последний оценённый товар **item_idx** как правильный ответ для проверки рекомендаций. Учитываются только пользователи, присутствующие в обучающей выборке."
      ],
      "metadata": {
        "id": "oDpzVAg9XHCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_items = test_df[test_df['user_idx'] < len(user_map)].set_index('user_idx')['item_idx']"
      ],
      "metadata": {
        "id": "-d3DEasd3Es7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для оценки качества рекомендаций используется метрика Hit@10. Она показывает долю пользователей, для которых правильный товар (последний оценённый в тесте) попал в топ-10 рекомендованных моделью позиций. Чем выше значение Hit@10, тем лучше модель предсказывает релевантные рекомендации"
      ],
      "metadata": {
        "id": "kSIzcNMhXlBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hit = 0\n",
        "total = 0\n",
        "\n",
        "for user_idx, true_item in test_items.items():\n",
        "    # model.recommend returns a tuple of (item_ids, scores)\n",
        "    recommended_items, _ = model.recommend(\n",
        "        userid=user_idx,\n",
        "        user_items=ratings_csr[user_idx],\n",
        "        N=10,\n",
        "        filter_already_liked_items=True\n",
        "    )\n",
        "\n",
        "    if true_item in recommended_items:\n",
        "        hit += 1\n",
        "    total += 1\n",
        "\n",
        "hit_rate = hit / total\n",
        "print(f'Hit@10: {hit_rate:.4f}')"
      ],
      "metadata": {
        "id": "2a3GJj0C3I1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы получили достаточно хороший результат по метрике **Hit@10 — 0.4534**, что означает, что почти у половины пользователей правильный товар попадает в топ-10 рекомендаций модели."
      ],
      "metadata": {
        "id": "iyxUD-iOXwKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "подбор оптимальных гиперпараметров модели для достижения наилучших результатов и повышения качества рекомендаций."
      ],
      "metadata": {
        "id": "M85eQZ4ZYbON"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98c86328"
      },
      "source": [
        "# Определяем сетку гиперпараметров\n",
        "factors = [50, 100]\n",
        "regularization = [0.01, 0.1]\n",
        "iterations = [15, 25]\n",
        "\n",
        "# Создаем все возможные комбинации гиперпараметров\n",
        "grid = list(itertools.product(factors, regularization, iterations))\n",
        "\n",
        "best_hit_rate = 0\n",
        "best_params = {}\n",
        "\n",
        "# Создаем словарь {user: [items]} для обучающих данных для быстрой проверки\n",
        "train_user_items = train_df.groupby('user_idx')['item_idx'].apply(list).to_dict()\n",
        "\n",
        "for f, r, i in grid:\n",
        "    print(f\"Training with factors={f}, regularization={r}, iterations={i}\")\n",
        "\n",
        "    # Обучаем модель\n",
        "    model = AlternatingLeastSquares(factors=f, regularization=r, iterations=i, random_state=42)\n",
        "    model.fit(ratings_csr)\n",
        "\n",
        "    # --- Считаем Hit@10 на трейне ---\n",
        "    train_hit = 0\n",
        "    # Проходим по всем пользователям в обучающей выборке\n",
        "    for user_idx, true_items in train_user_items.items():\n",
        "        recommended_items, _ = model.recommend(\n",
        "            userid=user_idx,\n",
        "            user_items=ratings_csr[user_idx],\n",
        "            N=10,\n",
        "            filter_already_liked_items=False # Важно: не фильтруем уже купленное\n",
        "        )\n",
        "        # Проверяем, есть ли хотя бы одно совпадение\n",
        "        if any(item in true_items for item in recommended_items):\n",
        "            train_hit += 1\n",
        "\n",
        "    train_hit_rate = train_hit / len(train_user_items)\n",
        "    print(f'Train Hit@10: {train_hit_rate:.4f}')\n",
        "\n",
        "    # --- Считаем Hit@10 на тесте ---\n",
        "    test_hit = 0\n",
        "    for user_idx, true_item in test_items.items():\n",
        "        recommended_items, _ = model.recommend(\n",
        "            userid=user_idx,\n",
        "            user_items=ratings_csr[user_idx],\n",
        "            N=10,\n",
        "            filter_already_liked_items=True # На тесте фильтруем\n",
        "        )\n",
        "\n",
        "        if true_item in recommended_items:\n",
        "            test_hit += 1\n",
        "\n",
        "    test_hit_rate = test_hit / len(test_items)\n",
        "    print(f'Test Hit@10: {test_hit_rate:.4f}\\n')\n",
        "\n",
        "    # Сохраняем лучшую модель по результатам на ТЕСТЕ\n",
        "    if test_hit_rate > best_hit_rate:\n",
        "        best_hit_rate = test_hit_rate\n",
        "        best_params = {'factors': f, 'regularization': r, 'iterations': i}\n",
        "\n",
        "print(f\"\\nBest Test Hit@10: {best_hit_rate:.4f}\")\n",
        "print(f\"Best params: {best_params}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92449d68"
      },
      "source": [
        "# 1. Обучение финальной модели с лучшими параметрами\n",
        "best_params = {'factors': 100, 'regularization': 0.01, 'iterations': 25}\n",
        "final_model = AlternatingLeastSquares(**best_params, random_state=42)\n",
        "final_model.fit(ratings_csr)\n",
        "\n",
        "# 2. Функция для получения рекомендаций\n",
        "def get_recommendations(user_id, model, n=10):\n",
        "    # Проверяем, есть ли такой пользователь в нашей карте\n",
        "    if user_id not in user_map:\n",
        "        return f\"Пользователь {user_id} не найден в обучающей выборке.\"\n",
        "\n",
        "    # Получаем внутренний индекс пользователя\n",
        "    user_idx = user_map[user_id]\n",
        "\n",
        "    # Получаем рекомендации\n",
        "    recommended_item_idxs, _ = model.recommend(\n",
        "        userid=user_idx,\n",
        "        user_items=ratings_csr[user_idx],\n",
        "        N=n,\n",
        "        filter_already_liked_items=True\n",
        "    )\n",
        "\n",
        "    # Преобразуем индексы товаров обратно в ProductId\n",
        "    recommended_product_ids = [item_map_inv[idx] for idx in recommended_item_idxs]\n",
        "\n",
        "    return recommended_product_ids\n",
        "\n",
        "# 3. Пример использования\n",
        "# Возьмем случайного пользователя из тестового набора\n",
        "example_user_id = test_df['UserId'].iloc[5]\n",
        "\n",
        "print(f\"Рекомендации для пользователя: {example_user_id}\\n\")\n",
        "\n",
        "# Получаем и выводим рекомендации\n",
        "recommendations = get_recommendations(example_user_id, final_model)\n",
        "for i, product_id in enumerate(recommendations):\n",
        "    print(f\"{i+1}. ProductId: {product_id}\")\n",
        "\n",
        "# Для контекста, давайте посмотрим, что этот пользователь покупал раньше\n",
        "print(\"\\nИстория покупок этого пользователя (из train):\")\n",
        "display(train_df[train_df['UserId'] == example_user_id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рекомендации для пользователя: **A1017Q5HHWNALE**"
      ],
      "metadata": {
        "id": "H7-S80AD5Efb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dd6e374"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# 1. Подготовка текстов: берем столбец 'Text'\n",
        "#    Заполняем возможные пропуски пустой строкой\n",
        "item_full_texts = df[['ProductId', 'Text']].drop_duplicates('ProductId').set_index('ProductId')\n",
        "item_full_texts['Text'] = item_full_texts['Text'].fillna('')\n",
        "\n",
        "# Упорядочим тексты в том же порядке, что и в item_map\n",
        "ordered_texts = item_full_texts.reindex(item_map.keys())['Text']\n",
        "\n",
        "# 2. Создаем новую TF-IDF матрицу\n",
        "#    Используем немного больше признаков, так как тексты богаче\n",
        "tfidf_full = TfidfVectorizer(max_features=10000, stop_words='english')\n",
        "tfidf_matrix_full = tfidf_full.fit_transform(ordered_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF матрица построена по колонке Text. Размерность: (34339, 10000)"
      ],
      "metadata": {
        "id": "eSh1dgai5pGl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed852fa1"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Словарь для хранения финальных переранжированных рекомендаций (на основе полных текстов)\n",
        "reranked_full_text_recs = {}\n",
        "\n",
        "# Проходим по пользователям и их топ-20 ALS рекомендациям\n",
        "for user_id, recommended_items in als_top_20_recommendations.items():\n",
        "\n",
        "    # 1. Получаем историю покупок пользователя (индексы товаров)\n",
        "    user_history_items = train_df[train_df['user_idx'] == user_id]['item_idx'].values\n",
        "\n",
        "    if len(user_history_items) == 0:\n",
        "        continue\n",
        "\n",
        "    # 2. Получаем TF-IDF векторы для истории и для рекомендаций из НОВОЙ матрицы\n",
        "    history_vectors = tfidf_matrix_full[user_history_items]\n",
        "    recommended_vectors = tfidf_matrix_full[recommended_items]\n",
        "\n",
        "    # 3. Считаем косинусное сходство\n",
        "    similarity_matrix = cosine_similarity(recommended_vectors, history_vectors)\n",
        "\n",
        "    # 4. Для каждой рекомендации считаем среднюю схожесть со всей историей\n",
        "    avg_similarity = similarity_matrix.mean(axis=1)\n",
        "\n",
        "    # 5. Сортируем и выбираем топ-10\n",
        "    reranked_indices = np.argsort(avg_similarity)[::-1]\n",
        "    top_10_reranked = [recommended_items[i] for i in reranked_indices[:10]]\n",
        "\n",
        "    reranked_full_text_recs[user_id] = top_10_reranked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переранжирован топ-10 рекомендаций для 20 366 пользователей на основе текстового содержимого ('Text'). Используемые тексты были преобразованы с помощью TF-IDF векторизации, что позволило учитывать семантическое сходство между пользователями и рекомендуемыми объектами."
      ],
      "metadata": {
        "id": "Mz_e7NQk54SO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a579bdfa"
      },
      "source": [
        "hit = 0\n",
        "total = 0\n",
        "\n",
        "for user_idx, true_item in test_items.items():\n",
        "    if user_idx in reranked_full_text_recs:\n",
        "        recommended_items = reranked_full_text_recs[user_idx]\n",
        "\n",
        "        if true_item in recommended_items:\n",
        "            hit += 1\n",
        "        total += 1\n",
        "\n",
        "if total > 0:\n",
        "    hit_rate = hit / total\n",
        "    print(f'Hybrid Model (Full Text) Hit@10: {hit_rate:.4f}')\n",
        "else:\n",
        "    print(\"Не удалось рассчитать Hit@10.\")\n",
        "\n",
        "print(\"\\n--- Сводка результатов ---\")\n",
        "print(f\"Original ALS Hit@10: {best_hit_rate:.4f}\")\n",
        "print(f\"Hybrid (Summary) Hit@10: 0.2408\") # Значение из предыдущего запуска\n",
        "print(f\"Hybrid (Full Text) Hit@10: {hit / total:.4f}\" if total > 0 else \"N/A\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Итоговые результаты\n",
        "\n",
        "Производительность всех моделей оценивалась по метрике **Hit@10** (доля пользователей, для которых правильный товар попал в топ-10 рекомендаций).\n",
        "\n",
        "| Модель | Описание | Hit@10 |\n",
        "| :--- | :--- | :--- |\n",
        "| **Original ALS** | Коллаборативная фильтрация | 0.4542 |\n",
        "| **Hybrid (Summary)** | ALS + TF-IDF на кратких описаниях | 0.2408 |\n",
        "| **Hybrid (Full Text)** | ALS + TF-IDF на полных текстах | **0.4667** |\n",
        "\n",
        "##  Выводы и дальнейшие шаги\n",
        "\n",
        "Чистая коллаборативная фильтрация (ALS) является очень сильной базовой моделью. Однако ее можно улучшить с помощью гибридного подхода, если использовать качественные контентные данные. Полные тексты отзывов, в отличие от кратких summary, содержат достаточно сигнала для эффективного переранжирования.\n",
        "\n",
        "**Возможные дальнейшие шаги:**\n",
        "-   **Использовать BERT**: Применить более продвинутые языковые модели (BERT, RoBERTa) для создания семантических эмбеддингов текста, что может дать еще больший прирост качества.\n",
        "-   **Настройка гибридной модели**: Экспериментировать с размером окна кандидатов от ALS (например, брать топ-50 или топ-100) и весами, с которыми смешиваются оценки от ALS и контентной модели."
      ],
      "metadata": {
        "id": "TPMGKc1wZsMO"
      }
    }
  ]
}